# Lab 000 - Environment Setup

* Welcome to `K-Agent` Labs! 
* In this first lab, you'll set up your development environment with all the tools needed for the `K-Agent` infrastructure. 
* This lab covers `Docker`, `Kubernetes`, and the `K-Agent` labs environment container.

---

#### What you'll learn in this workshop:

- Install and configure required tools (Docker, kubectl, Helm, Ollama, MCP Inspector, K-Agent etc.)
- Build and run the K-Agent labs environment (Docker container or locally)
- Verify Kubernetes cluster connectivity 
- Prepare the MCP server setup

---

## 01. Prerequisites Installation

### ğŸ³ Docker Installation

=== "ï£¿ macOS"

    ```bash
    # Install Docker Desktop
    brew install --cask docker
    
    # Start Docker Desktop from Applications
    # Or use command line:
    open /Applications/Docker.app
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"

    ```bash
    # Update package index
    sudo apt-get update
    
    # Install Docker
    curl -fsSL https://get.docker.com | sh
    
    # Add user to docker group
    sudo usermod -aG docker $USER
    
    # Restart session or run:
    newgrp docker
    ```

=== "ğŸ§ Linux (CentOS)"

    ```bash
    # Set up the repository
    sudo yum install -y yum-utils
    sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
    # Install Docker
    sudo yum install -y docker-ce docker-ce-cli containerd.io
    # Start Docker
    sudo systemctl start docker
    # Add user to docker group
    sudo usermod -aG docker $USER
    # Restart session or run:
    newgrp docker

    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Docker is pre-installed in Cloud Shell
    docker --version
    ```

### â˜¸ï¸ kubectl Installation

=== "ï£¿ macOS"

    ```bash
    brew install kubectl
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"

    ```bash
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
    ```

=== "ğŸ§ Linux (CentOS)"

    ```bash
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" 
    sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # kubectl is pre-installed
    kubectl version --client
    ```

### âš“ Helm Installation

=== "ï£¿ macOS"

    ```bash
    brew install helm
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"

    ```bash
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    ```

=== "ğŸ§ Linux (CentOS)"

    ```bash
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Helm is pre-installed
    helm version
    ```

### ğŸ™ Git Installation

=== "ï£¿ macOS"

    ```bash
    brew install git
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"

    ```bash
    sudo apt-get install -y git
    ```

=== "ğŸ§ Linux (CentOS)"

    ```bash
    sudo yum install -y git
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Git is pre-installed
    git --version
    ```

### ğŸ Python3 Installation

=== "ï£¿ macOS"

    ```bash
    brew install python
    ``` 

=== "ğŸ§ Linux (Ubuntu/Debian)"

    ```bash
    sudo apt-get install -y python3 python3-pip
    ```

=== "ğŸ§ Linux (CentOS)"

    ```bash
    sudo yum install -y python3 python3-pip
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Python3 is pre-installed
    python3 --version
    ```

### ğŸ“¦ Node.js Installation

=== "ï£¿ macOS"

    ```bash
    brew install node
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"
    ```bash
    sudo apt-get install -y nodejs npm
    ``` 

=== "ğŸ§ Linux (CentOS)"

    ```bash
    sudo yum install -y nodejs npm
    ```
=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Node.js is pre-installed
    node --version
    ```
 
### ğŸ¤– Ollama Installation

=== "ï£¿ macOS"

    ```bash
    brew install ollama
    
    # Start Ollama service
    ollama serve
    ``` 
=== "ğŸ§ Linux (Ubuntu/Debian)"
    ```bash
    curl -fsSL https://ollama.ai/install.sh | sh
    
    # Start Ollama service
    ollama serve
    ```
=== "ğŸ§ Linux (CentOS)"
    ```bash
    curl -fsSL https://ollama.ai/install.sh | sh

    # Start Ollama service
    ollama serve
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Ollama is not supported in Cloud Shell
    echo "Ollama is not supported in Cloud Shell"
    ```
    
### ğŸ” MCP Inspector Installation

=== "ï£¿ macOS"

    ```bash
    npm install -g @modelcontextprotocol/inspector
    ```

=== "ğŸ§ Linux (Ubuntu/Debian)"
    ```bash
    npm install -g @modelcontextprotocol/inspector
    ```

=== "ğŸ§ Linux (CentOS)"
    ```bash
    npm install -g @modelcontextprotocol/inspector
    ```

=== "â˜ï¸ GCP Cloud Shell"
    ```bash
    npm install -g @modelcontextprotocol/inspector
    ``` 

### Kubernetes Cluster Setup (minikube)

=== "ï£¿ macOS"

    ```bash
    brew install minikube
    ``` 
=== "ğŸ§ Linux (Ubuntu/Debian)"
    ```bash
    curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    sudo install minikube-linux-amd64 /usr/local/bin/minikube
    ``` 
=== "ğŸ§ Linux (CentOS)"
    ```bash
    curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    sudo install minikube-linux-amd64 /usr/local/bin/minikube
    ```
=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    # Minikube is already installed in Cloud Shell
    minikube version
    ```

### Kubernetes Cluster Setup (kind)

=== "ï£¿ macOS"

    ```bash
    brew install kind
    ``` 

=== "ğŸ§ Linux (Ubuntu/Debian)"
    ```bash
    curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
    chmod +x ./kind
    sudo mv ./kind /usr/local/bin/kind
    ```

=== "ğŸ§ Linux (CentOS)"
    ```bash
    curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
    chmod +x ./kind
    sudo mv ./kind /usr/local/bin/kind
    ```

=== "â˜ï¸ GCP Cloud Shell"

    ```bash
    Kind is not supported in Cloud Shell - Use minikube instead
    ``` 

---

## 02. Verify Tools Installation

* Verify that all the tools are installed
```bash
# Verify Docker
docker --version
# Verify kubectl
kubectl version --client
# Verify Helm
helm version
# Verify Git
git --version
# Verify Python3
python3 --version
# Verify Node.js
node --version
# Verify Ollama (if installed)
ollama --version
# Verify MCP Inspector
mcp-inspector --version 
# Verify Kind (if installed)
kind --version
# Verify Minikube (if installed)
minikube version
# Verify Cluster Info (if cluster is running)
kubectl cluster-info
```

---

## 03. Install the K-Agent 

* The `K-Agent` labs environment is the fundamental building block for all labs.
* Its an Open Source framework to write MCP tools and interact with Kubernetes clusters.

=== "ï£¿ macOS" 
    ```bash
    brew install kagent
    ```
=== "ğŸ§ Linux (Ubuntu/Debian)" 
    ```bash
    curl https://raw.githubusercontent.com/kagent-dev/kagent/refs/heads/main/scripts/get-kagent | bash
=== "ğŸ§ Linux (CentOS)" 
    ```bash
    curl https://raw.githubusercontent.com/kagent-dev/kagent/refs/heads/main/scripts/get-kagent | bash
    ```
=== "â˜ï¸ GCP Cloud Shell" 
    ```bash
    curl https://raw.githubusercontent.com/kagent-dev/kagent/refs/heads/main/scripts/get-kagent | bash
    ```

#### Verifty K-Agent Installation

  ```bash
  kagent version
  ```

---

## 04. Ollama Setup

* Ollama will be used as our LLLM model for the labs.
* Ollama is a local LLM server that allows you to run large language models on your machine.
* Ollama supports various models, for example: Qwen and Llama.
* We will ise the `qwen3-coder` model which is optimized for coding tasks or the `gpt-oos` model.  


!!! info "Pulling Models (Ollama)"
    * Pulling models can take a while depending on your internet speed and system performance.
    * You can skip this step and return to it later when needed.

#### Setup Ollama models

```bash
# Start Ollama service
ollama serve

# In a new terminal, pull the qwen3-coder model (optimized for coding tasks)
ollama pull qwen3-coder:30b

# Alternatively, pull the gpt-oos model
ollama pull gpt-oos:7b

# Verify
ollama list
```

### Pull a Model

```bash
# In a new terminal, pull the qwen3-coder model (optimized for coding tasks)
ollama pull qwen3-coder:30b

# Verify
ollama list
```

---

## 07. Verify Setup

* Let's verify your setup by running a simple test.

#### Task 01: Check Cluster Information

  ```bash

  # Check cluster info
  kubectl cluster-info
  kubectl get nodes
  kubectl get namespaces
  ```

**Exercise 2: Test Container Environment**

```bash
# Start labs environment if not running
cd labs-environment
docker compose up -d

# Execute commands in container
docker exec kagent-controller bash -c "
echo '=== Environment Check ==='
echo 'Node.js:' \$(node --version)
echo 'Python:' \$(python --version)
echo 'kubectl:' \$(kubectl version --client --short)
echo 'Helm:' \$(helm version --short)
echo '========================='
"
```

**Expected Output:**
```
=== Environment Check ===
Node.js: v18.x.x
Python: Python 3.10.x
kubectl: Client Version: v1.28.x
Helm: v3.13.x
=========================
```

---

## 08. Troubleshooting

!!! warning "Container Won't Start"
    If the container fails to start, check:
    ```bash
    docker compose logs
    docker images | grep kagent
    docker ps -a
    ```

!!! warning "Kubectl Not Working in Container"
    If kubectl commands fail in the container:
    ```bash
    # Verify kubeconfig is mounted correctly
    docker exec kagent-controller ls -la /root/.kube/
    
    # Try copying kubeconfig again
    cp ~/.kube/config $(git rev-parse --show-toplevel)//runtime/.kube/config
    
    # Restart container
    cd labs-environment
    docker compose restart
    ```

!!! warning "Platform Issues (M1/M2 Mac)"
    If you encounter platform errors:
    ```bash
    # Verify platform in .env file
    cat labs-environment/.env
    
    # Should show: TARGET_PLATFORM=linux/arm64
    # If not, update it manually
    ```

